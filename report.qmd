---
title: "S&DS 425/625 Report"
date: "`r Sys.Date()`"
author: "Elder Veliz & Emmanuelle Brindamour"
format: pdf
output:
  pdf_document: default
  word_document: default
urlcolor: blue
---

```{r, echo=FALSE}
suppressMessages({
  library(caret)
  library(ggplot2)
  library(ggcorrplot)
  library(janitor)    # Clean col names
  library(nnet)       # Multinomial
  library(pubtheme)
  library(ranger)     # Random forest
  library(sf)
  library(tidyverse)
})

# Constants
REPRODUCE <- FALSE
set.seed(425)

# Read CSV file
monthly_clean <- read_csv("monthly_clean.csv", show_col_types = FALSE)
monthly_clean <- monthly_clean |>
  clean_names() |>
  mutate(
    dominant_landcover = str_to_lower(str_trim(dominant_landcover)),
    year = factor(image_year),
    season = factor(season, 
                    levels = c("Winter", "Spring", "Summer", "Fall"), 
                    ordered = TRUE
                    ),
    veg = factor(veg),
    east_west = factor(east_west),
    north_south = factor(north_south),
    elevation_bins = factor(elevation_bins),
    dominant_landuse = factor(dominant_landuse),
    dominant_landcover = factor(dominant_landcover),
    month = factor(month)
  ) |>
  select(-image_year)
  
# # Convert to sf object
# data <- st_as_sf(
#   monthly_clean,
#   coords = c("lon", "lat"),
#   crs = 4326
# )
```

# Abstract

An overview of your report, including one or so sentences on each of these:

-   a non-technical description of the problem you are trying to solve or the question you are trying to answer, and why you are trying to answer that question
-   a non-technical description of the data, where it came from, and what it contains, including possibly the predictors, the outcome, and the observations
-   a non-technical description of what kind of analysis you did, including high-level description of what the predictors were, what the outcome was, and how to interpret the results of the model
-   a brief summary of the models that are used
-   a non-technical description of the results of the model and main takeaways.

An abstract is one paragraph with text only and is aimed at a technical audience. This appears at the beginning of the report.

# Executive Summary

An executive summary is typically longer than the abstract, up to a page, could possibly contain key visualizations, tables, or other figures that help communicate either the raw data or the results of the model, and is intended for someone outside of the data science/analytics team of an organization. It is important to be as concise as possible, and describe each of those points above without using language that is overly technical and not part of commonly used English. The executive summary is a separate document.

Note that in the abstract, executive summary, and throughout the report you should avoid using first-person singular pronouns like "I" and "me", even if you are the only author. Use "we" or use passive voice.

# Introduction

Understanding and predicting changes in land cover and land use over time is critical for addressing pressing environmental challenges, such as climate change, deforestation, urbanization, and agricultural productivity. Remote sensing data, particularly from satellite imagery, provides a powerful tool for monitoring these changes over large geographic areas and long time periods. By leveraging satellite-derived spectral bands and vegetation indices, such as the Normalized Difference Vegetation Index (NDVI), researchers can classify land cover types, assess their spatial-temporal dynamics, and derive actionable insights for decision-making in environmental management.

The motivation for this project arises from the need to integrate spatial and temporal dimensions into land cover modeling. While static models offer a snapshot of land cover at a *single* point in time, they fail to capture seasonal oscillations, inter-annual variability, and spatial dependencies inherent in natural systems. For example, vegetation exhibits predictable seasonal cycles that can be modeled using sinusoidal functions, revealing patterns in NDVI amplitude and frequency that correspond to land cover types. Additionally, nearby pixels often share similar characteristics due to ecological and geographic continuity, underscoring the importance of spatial relationships in classification models. These dynamics are not only scientifically interesting but also essential for improving the accuracy and interpretability of predictive models.

The data used in this study includes satellite-derived spectral bands (e.g., from the Landsat collection) and associated geospatial features, such as NDVI, land cover labels, and pixel locations. Temporal attributes such as month and year provide the foundation for modeling seasonal and long-term trends, while spatial attributes enable the incorporation of neighborhood-level statistics. Together, these features provide excellent data for exploring spatial-temporal patterns and improving land cover classification.

This paper is organized as follows: [Section 2](#data-exploration-and-visualization) provides an overview of the data, including exploratory analysis and visualizations that highlight key relationships and patterns. [Section 3](#modelinganalysis) describes the modeling approaches, including both regression and classification methods, with a focus on integrating temporal and spatial features into the predictive framework. [Section 4](#viz-results) discusses the visualization and interpretation of the results, comparing model performance and interpretability across approaches. Finally, [Section 5](#conclusions-recs) presents conclusions, recommendations, and ideas for future research directions, emphasizing the potential of spatial-temporal models for advancing land cover studies. By systematically exploring these dimensions, this project aims to contribute to a deeper understanding of land cover dynamics and their applications in environmental monitoring and management.

# Data Exploration and Visualization {#data-exploration-and-visualization}

To develop an effective predictive framework for land cover classification, a detailed exploration of the dataset is essential. This section investigates key characteristics of the data, examines relationships between predictors and the outcome variable, and provides visual evidence to support modeling assumptions. Through descriptive statistics and visualizations, we aim to justify the choice of features, highlight relevant patterns, and assess the validity of the modeling approach.

## Overview of the Dataset

The dataset comprises satellite-derived spectral bands (e.g., B1 through B7), the NDVI (Normalized Difference Vegetation Index), and metadata such as plot IDs, geographic coordinates (`lat` and `lon`), and temporal information (`month` and `year`). The primary outcome of interest is `dominant_landcover`, a categorical variable representing land cover classes. A review of the dataset variables follows:

-   `PlotID`: A unique identifier for each observation.
-   `Month` and `Year`: Categorical, temporal features indicating the month and year of the observation.
-   `SR_B1`: A continuous measurement of the "blue" spectral band, which captures visible blue light and is sensitive to water bodies and atmospheric aerosols.
-   `SR_B2`: A continuous measurement of the "green" spectral band, which captures visible green light and is sensitive to vegetation health and possibly land-water boundaries.
-   `SR_B3`: A continuous measurement of the "red" spectral band, which captures visible red light and is usually used to capture chlorophyll absorption in vegetation.
-   `SR_B4`: A continuous measurement of the "near-infrared" spectral band, which captures near-infrared light and is sensitive to vegetation density.
-   `SR_B5`: A continuous measurement of the "shortwave infrared 1" spectral band, which captures shortwave infrared light and is sensitive to moisture content in soil and vegetation.
-   `SR_B7`: A continuous measurement of the "shortwave infrared 2" spectral band, which captures shortwave infrared light and differentiates vegetation stress, soil properties, and geology.
-   `NDVI`: A continuous measurement of the Normalized Difference Vegetation Index, which quantifies vegetation density and health based on the contrast between red and near-infrared light (effectively, a non-linear function of `SR_B3` and `SR_B4`).
-   `Lat` and `Lon`: The latitude and longitude coordinates of the pixel.
-   `Dominant_Landcover`: A categorical outcome variable representing the dominant land cover class at the pixel level.
-   `Dominant_LandUse`: A categorical outcome variable representing the dominant land use class at the pixel level.
-   `Season`: A categorical variable for the season of observation.
-   `Veg`: A binary variable indicating whether the pixel's dominant landcover is vegetated (1 for "Grass/Forb/Herb", "Shrubs", and "Trees") or non-vegetated (0 for "Snow/Ice", "Impervious", "Barren", and "Water").
-   `EastWest`: A binary variable indicating whether the pixel is located east (1) or west (0) of the median longitude.
-   `NorthSouth`: A binary indicating whether the pixel is located north (1) or south (0) of the median latitude.
-   `Elevation_meters`: A continuous measurement of the elevation in meters above sea level at the pixel location.
-   `Elevation_Bins`: A categorical variable representing the elevation range of the pixel.

## Exploration of Outcome

```{r, echo=FALSE, fig.width=8, fig.height=4, out.width="100%", fig.align="center"}
if (REPRODUCE) {
  # Calculate counts and proportions
  landcover_summary <- monthly_clean %>%
    count(dominant_landcover) %>%
    mutate(prop = n / sum(n),
           label = scales::percent(prop))
  
  # Plot the ordered bar chart
  (p <- ggplot(landcover_summary, 
               aes(x = reorder(dominant_landcover, n), 
                   y = n, 
                   fill = dominant_landcover)
               ) +
    geom_bar(stat = "identity", width = 0.7) +
    geom_text(aes(label = label), vjust = -0.5, size = 3.5) +
    theme_pub() +
    labs(title = "Distribution of Land Cover Classes",
         x = "Land Cover Class", y = "Count") +
    scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
          legend.position = "none"))
  
  ggsave("sims/landcover_distribution.png", plot = p, width = 8, height = 4, dpi = 300)
} else {
  knitr::include_graphics("sims/landcover_distribution.png")
}
```

The distribution of land cover classes reveals substantial class imbalances, which will have important implications for the modeling process. The “Grass/Forb/Herb” class constitutes the majority, accounting for 45.27% of the observations, followed by the “Trees” class at 31.93%. Together, just these two classes dominate the dataset, representing over three-quarters of all observations. Their prevalence, nevertheless, is consistent with the ecological characteristics of United States.

In contrast, other land cover classes are significantly underrepresented. For instance, “Water” and “Shrubs” account for 9.09% and 8.24% of observations, respectively, while “Barren” and “Impervious” cover only 4.27% and 1.18%. The “Snow/Ice” class constitutes a mere 0.01% of observations, reflecting minimal spatial extent. This extreme imbalance suggests challenges for classification models, as underrepresented classes may be overshadowed during training, leading to biased predictions.

From a modeling perspective, class imbalance necessitates careful consideration of strategies to mitigate its effects. Techniques such as class weighting, oversampling of minority classes, or undersampling of dominant classes could be employed to ensure balanced representation during training. Furthermore, performance metrics beyond overall accuracy, such as the F1-score, precision-recall curves, or area under the ROC curve (AUC), will be considered to evaluate model performance more effectively across all classes.

## Exploration of Predictors

### Spectral Bands and NDVI:

Visualizing the spectral band values across different land cover types reveals a potential relationship between the outcome and predictor. Below, a boxplot of NDVI across land cover classes illustrates this relationship:

```{r, echo=FALSE, fig.width=8, fig.height=4, out.width="100%", fig.align="center"}
if (REPRODUCE) {
  (p <- ggplot(monthly_clean, aes(x = dominant_landcover, y = ndvi, fill = dominant_landcover)) +
    geom_boxplot() +
    theme_pub() +
    labs(title = "Distribution of NDVI by Land Cover Class",
         x = "Land Cover Class", y = "NDVI") +
    theme(axis.text.x = element_text(size = 8)))
  
    ggsave("sims/ndvi_boxplot.png", plot = p, width = 8, height = 4, dpi = 300)
} else {
  knitr::include_graphics("sims/ndvi_boxplot.png")
}
```

The distribution of NDVI values across land cover classes reveals both distinct patterns and notable overlaps that highlight the complexities of land cover classification. As shown in the boxplot visualization, classes such as “Trees” exhibit consistently higher NDVI values (though, with a relatively wide range), indicative of dense vegetation and strong photosynthetic activity. This aligns with ecological expectations, as tree canopies reflect substantial near-infrared light and absorb red light, resulting in high NDVI values. Conversely, classes like “Water” show consistently negative NDVI values, reflecting the spectral signature of water, which absorbs near-infrared light and reflects visible wavelengths.

However, certain classes, such as “Grass/Forb/Herb” and “Impervious,” demonstrate significant overlap in their NDVI distributions. This overlap may stem from seasonal variations in vegetation density or the heterogeneity of impervious surfaces, which can include both bare soil and constructed materials. Similarly, “Shrubs” and “Barren” exhibit NDVI ranges that overlap with both vegetative and non-vegetative classes, likely due to transitional or mixed land cover types.

This overlap underscores the need for advanced classification models that can handle complex, potentially *non*-linear relationships between predictors and outcomes. Random Forests and other ensemble methods, which are well-suited to datasets with overlapping class boundaries, are particularly promising. Additionally, incorporating supplementary predictors, such as spectral bands (e.g., B1-B7), temporal features (e.g., month and year), and spatial aggregates (e.g., mean NDVI of neighboring pixels), may further improve model performance by providing additional context for distinguishing between classes.

The variability within classes, as depicted by the interquartile ranges and outliers, also suggests the presence of heterogeneity within each land cover type. For example, the broader NDVI range for “Trees” may reflect differences in vegetation density, health, or canopy structure across regions. Similarly, the variability in “Grass/Forb/Herb” could be attributed to seasonal growth cycles or mixed vegetation types.

Ultimately, while NDVI provides meaningful separability for certain land cover classes, its limitations in distinguishing overlapping classes highlight the importance of *multi*-predictor models. This analysis justifies the use of advanced classifiers that integrate additional spectral, temporal, and spatial features to address the inherent complexity of land cover classification.

```{r, echo=FALSE, fig.width=8, fig.height=6, out.width="100%", fig.align="center"}
if (REPRODUCE) {
  long_data <- monthly_clean |>
    pivot_longer(cols = starts_with("sr_b"), names_to = "spectral_band", values_to = "value")
  
  (p <- ggplot(long_data, aes(x = dominant_landcover, y = value, fill = dominant_landcover)) +
    geom_boxplot() +
    theme_pub() +
    labs(title = "Distribution of Spectral Bands by Land Cover Class",
         x = "Land Cover Class", y = "Spectral Band Value") +
    facet_wrap(~spectral_band, scales = "free_y") +
    theme(axis.text.x = element_text(size = 8, angle = 45, hjust = 1)))

  ggsave("sims/spectral_bands_boxplot.png", plot = p, width = 8, height = 6, dpi = 300)
} else {
  knitr::include_graphics("sims/spectral_bands_boxplot.png")
}
```

Similarly, these boxplots faceted by spectral bands across land cover classes reveal key patterns that inform the potential predictors' utility for classification. For Bands 1, 2, and 3, which correspond to the visible blue, green, and red portions of the spectrum, the distribution of values remains relatively constant across the bands. This limited variability suggests strong collinearity among these bands—suggesting the need for dimensionality reduction techniques, such as Principal Component Analysis (PCA), to consolidate their information into fewer predictors without sacrificing interpretability.

For Bands 5 and 7, which capture reflectance in the shortwave infrared (SWIR) region, the distributions show a similar pattern of consistency across bands, though with slightly more variability compared to the visible bands. These bands are known to be sensitive to moisture content and soil properties, which may provide complementary information to indices like NDVI. However, the moderate to strong inter-correlation observed between these bands also highlights the potential redundancy in their spectral information. As a result, selecting the most informative band or combining them into derived indices may enhance the model.

No single band provides clear separability between all land cover classes, as evidenced by the substantial overlap in their distributions. For example, vegetative classes such as “Shrubs,” “Grass/Forb/Herb,” and “Trees” share overlapping ranges across multiple bands, reflecting the shared spectral characteristics of these land cover types. This overlap suggests that relying on any *single* spectral band as a predictor is insufficient for robust land cover classification.

### Temporal Features:

The dataset includes monthly and yearly observations, enabling an analysis of seasonal oscillations and inter-annual trends. Below, we visualize temporal variations using time-series plots:

```{r, echo=FALSE, fig.width=8, fig.height=3.5, out.width="100%", fig.align="center"}
if (REPRODUCE) {
  (p <- ggplot(monthly_clean, aes(x = month, y = ndvi, color = dominant_landcover, group = dominant_landcover)) +
    geom_line(stat = "summary", fun = "mean") +
    theme_pub() +
    labs(title = "Monthly Trends in NDVI",
         x = "Month", y = "Mean NDVI"))
  
  ggsave("sims/ndvi_monthly.png", plot = p, width = 8, height = 3.5, dpi = 300)
  
  (p <- ggplot(monthly_clean, 
               aes(x = season, 
                   y = ndvi, 
                   color = dominant_landcover, 
                   group = dominant_landcover)
               ) +
    geom_line(stat = "summary", fun = "mean") +
    theme_pub() +
    labs(title = "Seasonal Trends in NDVI",
         x = "Season", y = "Mean NDVI"))
  
  ggsave("sims/ndvi_seasonal.png", plot = p, width = 8, height = 3.5, dpi = 300)
} else {
  knitr::include_graphics("sims/ndvi_monthly.png")
  knitr::include_graphics("sims/ndvi_seasonal.png")
}
```

The visualization of seasonal NDVI trends across land cover classes reveals distinct temporal patterns that align with ecological expectations. As shown in the time-series plot, land cover types such as “Trees”, “Grass/Forb/Herb”, and "Shrubs" exhibit clear seasonal peaks during the summer months (June to August), corresponding to periods of maximum photosynthetic activity and vegetation growth. The NDVI for these classes declines during the winter months (October to February), reflecting the dormancy or reduced vegetation cover typical of temperate climates.

“Snow/Ice”, on the other hand, shows a very prominent decline in NDVI in the late-Winter and Spring months (February to June), likely due to the melting of snow and ice, which reduces the reflectance in near-infrared bands. Conversely, “Water” maintains relatively stable NDVI values throughout the year, consistent with its spectral signature that is less influenced by seasonal changes. Classes like “Barren” and, albeit to a limited extent, “Impervious” also show minimal seasonal variation, as these land cover types are largely non-vegetative and therefore less responsive to seasonal shifts.

The overlap in seasonal NDVI patterns for certain classes (such as “Grass/Forb/Herb”, “Impervious”, and “Shrubs”) underscores the importance of incorporating temporal features into the classification framework. These temporal dynamics can be modeled using sinusoidal functions, where NDVI is represented as a combination of sine and cosine terms to capture periodic oscillations. For example: $\text{NDVI}(t) = A \cdot sin(2\pi \cdot f \cdot t + \phi) + B \cdot cos(2\pi \cdot f \cdot t + \phi)$, where $A$ and $B$ are the amplitudes, $f$ is the frequency (e.g., one cycle per year), $t$ is time (month or a numerical mapping of season), and $\phi$ is the phase shift. These derived features, such as amplitude and phase, can serve as additional predictors in classification models.

The seasonal trends also highlight the need for models that account for temporal dependencies. Incorporating features like month or Fourier-derived seasonal components into machine learning classifiers can improve their ability to distinguish between classes with overlapping NDVI ranges. For example, while “Grass/Forb/Herb” and “Shrubs” may have similar NDVI distributions at specific times of the year, their seasonal trajectories clearly differ, providing an additional dimension for separation.

Overall, the observed periodic patterns in NDVI justify the inclusion of temporal features in the modeling framework. These features not only enhance the interpretability of the models but also provide a biologically meaningful basis for improving classification accuracy.

```{r, echo=FALSE, fig.width=8, fig.height=6, out.width="100%", fig.align="center"}
if (REPRODUCE) {
  (p <- ggplot(long_data, 
               aes(x = season, 
                   y = value, 
                   color = dominant_landcover, 
                   group = dominant_landcover)
               ) +
    geom_line(stat = "summary", fun = "mean", linewidth = 1) +
    theme_pub() +
    labs(title = "Seasonal Trends in Spectral Bands by Land Cover Class",
         x = "Season", y = "Mean Value") +
    facet_wrap(~spectral_band, scales = "free_y") +
    theme(
      axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
      strip.text = element_text(size = 10, face = "bold")
    ))
  ggsave("sims/spectral_bands_seasonal.png", plot = p, width = 8, height = 6, dpi = 300)
} else {
  knitr::include_graphics("sims/spectral_bands_seasonal.png")
}
```

We extend this analysis to the spectral bands. The seasonal trends in spectral bands across land cover classes reveal similar periodicity, particularly in the "Snow/Ice" class, which exhibits distinct seasonal variations across all bands. This behavior is most pronounced in bands 1, 2, and 3 (visible spectrum), where reflectance values peak in the Spring, likely due to snow and ice melt influencing surface properties. The similarity in trends across these bands reinforces their shared sensitivity to visible light, suggesting they capture *redundant* information.

Shortwave infrared bands 5 and 7 display more nuanced seasonal trends, particularly for “Trees” and “Barren.” These classes show clear increases in reflectance during summer, for "Trees" aligning with the seasonal growth of vegetation and moisture-related changes that SWIR bands are sensitive to. Notably, the “Impervious” class remains relatively stable across all seasons in these bands, reflecting the consistency of its surface properties. The overall variability in Band 4 is less pronounced compared to Bands 5 and 7, which suggests SWIR bands may provide additional discriminative power for land cover classes with more prominent moisture or structural changes.

```{r, echo=FALSE, fig.width=8, fig.height=4, out.width="100%", fig.align="center"}
if (REPRODUCE) {
  (p <- ggplot(monthly_clean, 
               aes(x = year, 
                   y = ndvi, 
                   color = dominant_landcover, 
                   group = dominant_landcover)
               ) +
    geom_line(stat = "summary", fun = "mean") +
    theme_pub() +
    labs(title = "Yearly Trends in NDVI",
         x = "Year", y = "Mean NDVI") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)))
  
  ggsave("sims/ndvi_yearly.png", plot = p, width = 8, height = 4, dpi = 300)
} else {
  knitr::include_graphics("sims/ndvi_yearly.png")
}
```

```{r, echo=FALSE, fig.width=8, fig.height=6, out.width="100%", fig.align="center"}
if (REPRODUCE) {
  (p <- ggplot(long_data, 
               aes(x = year, 
                   y = value, 
                   color = dominant_landcover, 
                   group = dominant_landcover)
               ) +
  geom_line(stat = "summary", fun = "mean", linewidth = 1) +
  theme_pub() +
  labs(title = "Yearly Trends in Spectral Bands by Land Cover Class",
       x = "Year", y = "Mean Value") +
  facet_wrap(~ spectral_band, scales = "free_y") +
  theme(
    axis.text.x = element_text(size = 6, angle = 90),
    strip.text = element_text(size = 10, face = "bold")
  ))
  
  ggsave("sims/spectral_bands_yearly.png", plot = p, width = 8, height = 6, dpi = 300)
} else {
  knitr::include_graphics("sims/spectral_bands_yearly.png")
}
```

The analysis of yearly NDVI trends provides valuable insights into the stability and variability of vegetation dynamics across different land cover classes from 2000 to 2021 (the time range we focus on). The “Trees” class demonstrates consistently high NDVI values throughout the period, with a slight upward trend in recent years. This stability reflects the resilience of forested areas within the dataset and suggests minimal deforestation or even reforestation in some regions. Similarly, the “Grass/Forb/Herb” and “Shrubs” classes exhibit relatively stable NDVI values with limited inter-annual variability, indicative of consistent vegetation cover. These trends highlight the long-term stability of these vegetative land cover types, which is critical for assessing ecosystem health and predicting land cover changes.

In contrast, the “Snow/Ice” class exhibits considerable variability in NDVI, particularly between 2002 and 2005. This fluctuation may be attributable to climatic factors such as variations in snow and ice coverage due to changing weather patterns or broader impacts of global warming. The unstable NDVI trend observed for this class aligns with the hypothesis of reduced snow and ice cover over time, signaling potential shifts in cryospheric dynamics that merit further investigation. Non-vegetative class “Barren” maintains consistently low NDVI values, reflecting their lack of vegetation and spectral characteristics. This stability over time indicates minimal changes in land use or surface conditions in areas dominated by barren land. The “Water” class similarly shows stable negative NDVI values near zero, confirming its spectral separability and consistency over the study period. Concerning is the nearly identical trends among "Impervious" and "Grass/Forb/Herb" which suggest distinguishing these classes will prove difficult.

The observed trends suggest that temporal features, such as year, may provide *limited* additional predictive power for classes like “Impervious” and “Grass/Forb/Herb,” given their relative stability. However, for classes like “Snow/Ice,” where inter-annual variability is more pronounced, temporal features may enhance the model’s ability to capture dynamic changes. Overall, this analysis underscores the potential of temporal trends in NDVI to provide meaningful insights into land cover changes while emphasizing the need for tailored modeling approaches that account for the *unique* characteristics of each land cover class.

The analysis of yearly spectral band trends aligns closely with the NDVI observations, particularly in the clear separability of the “Snow/Ice” and “Water” classes. “Snow/Ice” demonstrates pronounced periodicity across visible bands (B1, B2, B3), with reflectance peaks likely driven by seasonal variations in snow cover. The Water class, in contrast, maintains consistently low reflectance values across all bands, highlighting its distinct spectral signature.

For the remaining land cover classes, visible bands (B1, B2, B3) show limited variability, reaffirming their redundancy in distinguishing between vegetative and non-vegetative classes. However, Bands 5 (SWIR1) and 7 (SWIR2) provide more nuanced differences, particularly for classes like “Trees” and “Barren,” where seasonal and inter-annual changes are more evident.

## Exploration of Spatial Patterns

### Spatial Relationships:

The geographic proximity of pixels merits exploration of potential correlations between neighboring observations. A heatmap of NDVI values can highlight spatial continuity:

```{r, echo=FALSE, fig.width=8, fig.height=3.75, out.width="100%", fig.align="center"}
if (REPRODUCE) {
  (p <- ggplot(monthly_clean |> filter(year == 2010), 
               aes(x = lon, y = lat, color = ndvi)
               ) +
    geom_point(size = 0.5, alpha = 0.7) +
    theme_pub() +
    labs(title = "Spatial Distribution of NDVI",
         x = "Longitude", y = "Latitude", color = "NDVI") +
    theme(legend.position = "none"))
  
  ggsave("sims/ndvi_spatial.png", plot = p, width = 8, height = 3.75, dpi = 300)
} else {
  knitr::include_graphics("sims/ndvi_spatial.png")
}
```

```{r, echo=FALSE, fig.width=8, fig.height=4.5, out.width="100%", fig.align="center"}
if (REPRODUCE) {
  (p <- ggplot(long_data |> filter(year == 2010), 
               aes(x = lon, y = lat, color = value)
               ) +
    geom_point(size = 0.5, alpha = 0.9) +
    theme_pub() +
    labs(
      title = "Spatial Distribution of Spectral Bands",
      x = "Longitude", y = "Latitude", color = "Value"
    ) +
    facet_wrap(~spectral_band, scales = "free") +
    theme(
      axis.text.x = element_text(size = 8),
      axis.text.y = element_text(size = 8),
      strip.text = element_text(size = 10, face = "bold"),
      legend.position = "none")
   )
  
  ggsave("sims/spectral_bands_spatial.png", plot = p, width = 8, height = 4.5, dpi = 300)
} else {
  knitr::include_graphics("sims/spectral_bands_spatial.png")
}
```

The visualization of NDVI and spectral band values across the United States highlights the spatial continuity of the predictors, where adjacent pixels exhibit similar values due to shared environmental and land cover characteristics.

High NDVI values, indicative of dense vegetation and robust photosynthetic activity, are concentrated in the eastern U.S. and parts of the Pacific Northwest which are regions characterized by forested landscapes and favorable climatic conditions that support high vegetation density.

In contrast, areas with low NDVI values are predominantly located in the arid western and southwestern United States. These regions, dominated by deserts, sparse vegetation, and barren land, naturally exhibit reduced photosynthetic activity. The stability and clustering of NDVI in these regions emphasize the potential for spatial correlations to enhance predictive modeling. For example, neighboring pixels are likely to belong to the same land cover class, providing an opportunity to use spatial aggregates such as the mean or variance of NDVI values within a defined neighborhood as additional predictors in classification models.

Furthermore, the spatial clustering observed in the map suggests the importance of incorporating spatial relationships into the modeling framework. By considering the influence of nearby pixels, the model may better capture the continuity and heterogeneity inherent in natural landscapes. For instance, spatial smoothing or feature engineering techniques that aggregate NDVI values across a local neighborhood can provide additional context for distinguishing between land cover types with similar spectral signatures.

This analysis supports the hypothesis that spatial dependencies play a critical role in determining NDVI variability and, by extension, land cover classification. Incorporating spatial features may not only enhance model performance but also align with the underlying ecological processes that govern land cover patterns. We will leverage these spatial relationships by integrating *neighborhood-level* statistics.

## Preliminary Correlation Analysis

A correlation matrix of predictors (e.g., spectral bands and NDVI) helps identify multicollinearity, which may impact model selection:

```{r, echo=FALSE, fig.width=8, fig.height=6, out.width="100%", fig.align="center"}
if (REPRODUCE) {
  correlation_matrix <- cor(monthly_clean[, c(
    "sr_b1", 
    "sr_b2", 
    "sr_b3", 
    "sr_b4",
    "sr_b5",
    "sr_b7",
    "ndvi",
    "elevation_meters",
    "lat",
    "lon")], use = "complete.obs")
  
  # correlation matrix
  (p <- ggcorrplot(correlation_matrix, 
             type = "upper",
             lab = TRUE,
             lab_size = 3,
             colors = c("darkred", "white", "darkgreen"), # Gradient (neg to pos)
             outline.color = "black",
             legend.title = "Correlation",
             title = "Correlation Matrix of Continuous Predictors") +
    theme_pub() +
    theme(
      plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
      legend.text = element_text(size = 8),
      legend.title = element_text(size = 12, face = "bold"),
      axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
      axis.text.y = element_text(size = 10)
    ) +
    theme(axis.title.x=element_blank(), axis.title.y=element_blank()))
  
  ggsave("sims/correlation_matrix.png", plot = p, width = 8, height = 6, dpi = 300)
} else {
  knitr::include_graphics("sims/correlation_matrix.png")
}
```

The correlation matrix provides insights into the relationships among the continuous variables, highlighting both redundancies and potential predictors for land cover classification.

While NDVI exhibits weak to moderate negative correlations with several spectral bands, these relationships highlight the inherent complexity of vegetation dynamics and the limitations of *linear* correlation measures. Specifically, NDVI demonstrates weak negative correlations with the near-infrared band `SR_B4` (-0.21) and the shortwave infrared band `SR_B5` (-0.26), aligning with the fact that NDVI is a *non*-linear function of red and near-infrared reflectance. The weak linear correlation underscores that the predictive power of these bands may lie not in their independent contributions but in their interactions, which may be more effectively captured through non-linear models.

The visible bands `SR_B1`, `SR_B2`, and `SR_B3` exhibit near-perfect collinearity, with correlation coefficients exceeding 0.94. This strong interdependence indicates that these bands measure nearly identical surface properties in the visible spectrum, such as reflectance from bare soil, water, and vegetation—aligning with previously identified redundancies across the predictor categories. While these bands are critical for understanding vegetation absorption and reflection in the blue, green, and red ranges, their redundancy poses a risk of multicollinearity in predictive models. Without dimensionality reduction, their inclusion as independent predictors may lead to instability and overfitting.

Beyond the visible spectrum, the infrared bands `SR_B4`, `SR_B5`, and `SR_B7` show moderate to strong inter-correlations, with values above 0.6 in some cases. These bands capture distinct but related properties, including vegetation structure, moisture content, and thermal properties. While their interdependence is not *as* pronounced as the visible bands, it suggests complementary information that could enhance classification models when used judiciously. In contrast, spatial variables such as latitude and longitude display negligible correlations with NDVI and other spectral predictors, indicating that geographic location alone may not strongly predict vegetation health. Elevation, similarly, shows weak correlations across all variables, suggesting it may have a limited direct impact on spectral properties in this dataset. However, spatial variables could still prove valuable in capturing non-linear regional trends or serving as inputs for spatial-temporal models.

The observed correlations provide critical guidance for feature engineering and model selection. The weak correlations between NDVI and individual spectral bands further reinforce the need to explore non-linear models, such as Random Forests, that can capture complex interactions. At the same time, the high collinearity among certain bands necessitates dimensionality reduction to mitigate redundancy and improve computational efficiency. Incorporating indices such as NDVI or enhanced vegetation indices may allow for a more nuanced representation of vegetation health, leveraging the interplay of spectral bands more effectively. While spatial and elevation variables appear weakly correlated with NDVI, they may still play an important role in explaining regional variations when combined with other predictors.

```{r, echo=FALSE, fig.width=8, fig.height=4, out.width="100%", fig.align="center"}
ggplot(monthly_clean, aes(x = dominant_landcover, y = elevation_meters, fill = dominant_landcover)) +
  geom_boxplot(outlier.size = 0.5) +
  theme_pub() +
  labs(
    title = "Elevation Distribution Across Land Cover Classes",
    x = "Land Cover Class", y = "Elevation (meters)"
  ) +
  theme(axis.text.x = element_text(size = 8, angle = 45, hjust = 1),
        legend.position = "none")
```

## Assumptions for Modeling

From the data exploration, several assumptions emerge:

1.  Predictor-Outcome Relationships:
    -   Spectral bands and NDVI are assumed to have distinct distributions across land cover classes.
    -   Temporal features (e.g., month) contribute to variations in spectral responses, particularly in vegetated areas.
2.  Spatial Dependencies:
    -   The inclusion of spatial aggregates accounts for the influence of neighboring pixels, improving classification accuracy.
3.  Seasonal Patterns:
    -   NDVI and other vegetation-sensitive bands exhibit periodic trends, justifying sinusoidal modeling.

Justifying Model Choices

1.  Linear Models: NDVI trends suggest linear separability in some cases, making Ordinary Least Squares (OLS) a suitable baseline.

2.  Random Forests: To handle potential overlaps in spectral responses between classes, Random Forests are well-suited for non-linear decision boundaries.

3.  Temporal Models: Incorporating sinusoidal features into logistic regression or Random Forest classifiers accounts for seasonal oscillations, enhancing model performance.

4.  Spatial-Temporal Extensions: Models that combine spatial aggregates and temporal features provide a comprehensive framework for land cover classification.

## Section Conclusion

This exploratory analysis establishes the relationships between predictors and the outcome variable, supports the inclusion of temporal and spatial features, and provides justification for model selection. The next section will focus on modeling approaches, detailing the assumptions, methodology, and evaluation metrics used to predict land cover classes.

# Modeling and Analysis {#modelinganalysis}

The objective of this section is to formalize and implement predictive models to classify land cover types using the predictors identified in the data exploration phase. The models we employ must address key challenges, including the complexity of spectral, temporal, and spatial relationships, overlapping class boundaries, and collinearity among predictors. This section details the regression and classification models tested, their assumptions, implementation, and evaluation.

## Problem Setup

The task involves predicting the dominant land cover class (`dominant_landcover`), a categorical variable with multiple classes, using a set of continuous and categorical predictors. Specifically:

-   Observation ($X$): Each row corresponds to a unique satellite-derived observation at a specific time (`year`, `month`) and geographic location (`lat`, `lon`).

-   Predictors (columns of $X$): Continuous predictors include spectral bands (`SR_B1`, `SR_B2`, … `SR_B7`), `NDVI`, elevation (`elevation_meters`), and spatial-temporal variables like `month`, `year`, and `season`. Derived spatial aggregates and sinusoidal features (e.g., sine/cosine terms) will also be introduced during feature engineering.

-   Outcome ($y$): The target variable is `dominant_landcover`, representing land cover classes such as “Trees,” “Water,” “Snow/Ice,” etc.

## Baseline Models: Linear Models

### Assumptions:

Linear models assume that the predictors have a linear relationship with the response variable, which is appropriate for continuous outcomes but must be adapted for classification tasks. Given that land cover classification involves categorical outcomes, we implement **multinomial logistic regression** as our baseline linear model.

### Model Specification:

The multinomial logistic regression model predicts the probability of a pixel belonging to a given class $C$ as follows:

$$
P(y=c | X) = \frac{\exp(\beta_{c_0} + \beta^\top_{c}X)}{\sum_{k=1}^{K} \exp(\beta_{k_0} + \beta^\top_{k}X)}, \forall c \in [1, K]
$$

where $X \in \mathbb{R}^{n \times p}$ represents the predictors (spectral bands, NDVI, temporal features), and $\beta_c$ are the coefficients for class $c$.

### Implementation:

We fit the multinomial logistic regression model with spectral bands (`SR_B1` to `SR_B7`), `NDVI`, and temporal feature `season`, elevation bins, vegetation indicator, and spatial features (`EastWest` and `NorthSouth`) as predictors. Collinearity among spectral band predictors will be mitigated using Principal Component Analysis (PCA) to reduce dimensionality.

```{r, echo=FALSE, fig.width=8, fig.height=4}
# Feature selection: Use PCA to reduce multicollinearity
pca_bands <- prcomp(
  monthly_clean[, c("sr_b1", "sr_b2", "sr_b3", "sr_b4", "sr_b5", "sr_b7")],
  center = TRUE,
  scale. = TRUE)

# Variance explained
pca_var <- pca_bands$sdev^2                  # Eigenvalues of each PC
pca_var_explained <- pca_var / sum(pca_var)  # Proportion of variance

# Create DataFrame for Plotting
pca_df <- data.frame(
  PC = paste0("PC", 1:length(pca_var)),
  Variance = pca_var_explained
)

# Plot Scree Plot
ggplot(pca_df, aes(x = PC, y = Variance)) +
  geom_col(fill = "steelblue") +
  geom_point(size = 3) +
  geom_line(aes(group = 1), color = "darkred", linetype = "dashed") +
  labs(
    title = "Scree Plot: Variance Explained by Principal Components",
    x = "Principal Component", y = "Proportion of Variance Explained"
  ) +
  theme_pub() +
  scale_y_continuous(breaks = seq(0.05, 1, by = 0.1))
```

The scree plot shows the proportion of variance explained by each Principal Component. The first principal component (PC1) accounts for approximately 75% of the variance, while the second principal component (PC2) explains an additional 15%, together explaining over 90% of the total variance. Beyond PC2, the contribution of additional components (PC3 to PC6) is minimal, collectively explaining less than 10% of the variance. This diminishing contribution is evident in the elbow of the curve, where the explained variance sharply declines after PC2.

Given this pattern, we retain only the first two principal components for downstream modeling, as they account for the vast majority of the variance in the spectral bands while significantly reducing dimensionality. Selecting only PC1 and PC2 enhances model simplicity and interpretability without substantial loss of information.

```{r, echo=FALSE}
pca_features <- as.data.frame(pca_bands$x[, 1:2]) # top 3 PCs

model_data <- cbind(
  pca_features,                                         # PCA-reduced spectral bands
  NDVI = monthly_clean$ndvi,                            # NDVI
  Season = as.factor(monthly_clean$season),             # Temporal feature: Season
  Elevation = as.factor(monthly_clean$elevation_bins),  # Elevation bins
  Veg = as.factor(monthly_clean$veg),                   # Vegetation indicator
  EastWest = as.factor(monthly_clean$east_west),        # Spatial: East/West
  NorthSouth = as.factor(monthly_clean$north_south),    # Spatial: North/South
  Outcome = monthly_clean$dominant_landcover            # Target: Land Cover Class
)

if (REPRODUCE) {
  # Fit multinomial logistic regression
  logistic_model <- multinom(Outcome ~ ., data = model_data)
  saveRDS(logistic_model, "sims/log_model.RDS")
} else {
  logistic_model <- readRDS("sims/log_model.RDS")
}

# Model summary
#summary(logistic_model)
```

### Performance Evaluation:

Model performance will be evaluated using accuracy, precision, recall, and F1-score. A confusion matrix will be generated to analyze misclassifications across land cover classes.

```{r, echo=FALSE}
# Predict on training data
predictions <- predict(logistic_model, model_data) # 66.52% using 3; 66.64% using 2 PCs
conf_matrix <- confusionMatrix(predictions, model_data$Outcome)
conf_matrix$table
```

### Interpretation:

The coefficients of the logistic model indicate the relative influence of each predictor (e.g., NDVI, PCA-derived features) on the probability of a pixel belonging to a specific land cover class. For example, higher NDVI values are expected to increase the likelihood of vegetation-related classes such as “Trees” or “Grass/Forb/Herb.”

### Appropriateness:

While linear models provide interpretability and establish baseline performance, their assumption of linear separability may limit their ability to distinguish overlapping land cover classes, particularly those with complex spectral signatures. CART produces simple, interpretable models in the form of decision trees, making it easy for domain experts and policymakers to understand and trust the results.

## Non-Linear Models

A common challenge in energy and environmental data analysis is capturing non-linear relationships. 

## CART (Classification and Regression Trees) Algorithm
CART algorithms excel at modeling non-linear and complex interactions between both continuous and categorical variables, which are common in environmental datasets. CART algorithms work well with raw data and require minimal preprocessing, such as scaling or normalization. CART can handle noisy and missing data effectively, making it a reliable choice for datasets with gaps or inconsistencies, which are often seen in environmental monitoring systems. 
CART forms the foundation of more advanced algorithms like Random Forest and Gradient Boosting, which are often recommended when higher accuracy is needed for predictive modeling. The CART algorithm builds a  single decision tree by recursively splitting the data based on a chosen criterion (e.g., Entropy). Then, it directly assigns a class label to the leaf nodes based on the majority vote in those nodes.
CART's use of a single decision tree can lead to overfitting, especially when the tree grows deep and captures noise in the training data. To counter this, CART can at times require pruning techniques, which can lead to a tradeoff between bias and variance. However, the interpretability and computational efficiency of CART models are significant advantages, as the decision rules are easy to understand and communicate to stakeholders.

## Implementation:
The monthly averages dataset was filtered to points within U.S. borders and assessed in year-wise batches, with unique entries defined by plotid. Landcover classes were dynamically encoded, and visualized on the GEE interface:
![Map of Visualized Data](sims/actual_map.png)
The CART model was trained on 70% of the dataset and tested on 30% of the dataset, using predictors: NDVI, SR_B1, SR_B2, SR_B3, SR_B4, SR_B5, SR_B7, elevation_meters (See full code [here](https://code.earthengine.google.com/27be438d2822e76c39af6aece7d61aad)).
For instance, for 2018, the data sizes were as follows;
* Total Observations: 24,411
* Training Set: 16,942 observations
* Testing Set: 7,469 observations

## Performance Evaluation
The CART model was evaluated using accuracy, precision, recall, and the kappa coefficient. It earned:
* An accuracy of 0.553, or 55.3%
* A kappa coefficient of 0.304
The classifier incorrectly classified 3339 observations, representing 44.7% of the testing set. There were 30 unique misclassification types, and we observed those 6 with the highest misclassification frequency:
1. Trees classified as Grass/Forb/Herb (805)
2. Grass/Forb/Herb classified as Trees (745)
3. Trees classified as Shrubs (382)
4. Shrubs classified as Trees (322)
5. Trees classified as Barren (192)
6. Barren classified as Trees (153)
These misclassifications were styled dynamically by type and visualized on the map to explore any geospatial groupings. We see that trees and grass are often misclassified as one another along the northeast, but grass is incorrectly classified as trees in the midwest. This shows that the model struggles to distinguish between these two classes in certain regions, but especially where grass is prevalent.
![Map of Top 6 Misclassifications Against Actual Values](sims/layeredmap.png)
Given certain classes appeared to host disproportionate misclassifications (e.g., Trees), we explored misclassification rates, precision, and recall by class, shown in the table. First, misclassification rates were calculated as follows;
$$
\text{Misclassification Rate} = \frac{\text{Misclassified Points in Class}}{\text{Total Points in Class}}
$$

While all classes have moderate to high misclassification rates, Snow, Impervious, Shrubs and Barren had significantly larger rates than other classes. The dispersion between rates is likely due to class imbalance in the training data, as certain classes were highly underrepresented relative to others, like Snow/ice (2 occurrences) against Grass/forb/herb (8,825 occurrences). Next, the two errors contributing to misclassification, predicting false positives and false negatives, was observed by calculating precision and recall. Precision by class  measures the proportion of true positive predictions out of all positive predictions made by the model:
$$
\text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}
$$
Recall by class measures the proportion of true positive predictions out of all actual positive instances in the dataset:
$$
\text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}
$$
When precision is less than recall for a given class, it suggests the model is overpredicting that class, resulting in many false positives. The table shows that Water, Grass/forb/herb and Barren are often incorrectly predicted for a certain point, which makes sense given their large representation in the training data. Conversely, when recall is less than precision, the model is underpredicting that class, resulting in many false negatives. For example, Trees and Shrubs are often missed by the model. Given these classes are not underrepresented in the training data, the model may be struggling to distinguish between them and other classes due to their similar spectral signatures.

| Landcover Type | Misclassifications | Misclassification Rate | Precision  | Recall  |
|----------------|--------------------|------------------------|------------|---------|
|Water           | 87                 | 0.24                   | 0.75       | 0.77    |
|Grass/forb/herb | 935                | 0.44                   | 0.55       | 0.56    |
|Trees           | 1502               | 0.38                   | 0.65       | 0.62    |
|Shrubs          | 498                | 0.79                   | 0.20       | 0.21    |
|Barren          | 226                | 0.69                   | 0.25       | 0.3     |
|Impervious      | 90                 | 0.93                   | 0.06       | 0.07    |
|Snow/Ice        | 1                  | 1.00                   | 0.00       | 0.00    |


The results reveal that the CART model, while providing a simple and interpretable solution, struggles to accurately classify land cover types due to the complexity of the data, and perhaps the lack of abundant labels proportionate to the geographic area covered by the dataset. To further our analysis, we created a second CART algorithm that uses our entire dataset as training in order to classify all pixels in a satellite image, from which the algorithm pulls new band values (see full code [here](https://code.earthengine.google.com/c3ff3c14701654ffd166e70e189f8ee6)). Given the time and computational power required to analyze such large satellite datasets, we focused on the state of New York for this application of the CART algorithm. The model was then evaluated on a 2018 image, and the results were visualized on the GEE interface:




and the limitations of a single decision tree. The model's performance is hindered by the high misclassification rates, particularly for classes with similar spectral signatures or underrepresented in the training data. To improve classification accuracy and address these challenges, we will explore ensemble methods like Random Forests, which can capture non-linear relationships and interactions more effectively.

## Random Forests

Given the limitations of linear models, Random Forests are introduced to capture non-linear relationships and feature interactions. Random Forests are ensemble models that construct multiple decision trees and combine their outputs to improve classification accuracy.

### Assumptions:

Random Forests make no assumptions about the functional form of the predictors and outcomes, making them highly flexible for complex datasets. They can handle multicollinearity, non-linear relationships, and high-dimensional predictors effectively.

###Implementation: The Random Forest model will include all predictors used in the multinomial model. Spatial aggregates (e.g., neighborhood means of NDVI) will be introduced as additional features to capture local spatial dependencies.


```{r}
if (REPRODUCE) {
  # Define the hyperparameter grid
  num_trees_list <- c(50, 100)          # Number of trees
  mtry_list <- c(2, 4, 6)               # Number of predictors sampled at each split
  max_depth_list <- c(10, 15, 20)       # Maximum depth of trees
  
  # Create a data frame to store results
  results <- expand.grid(num_trees = num_trees_list,
                         mtry = mtry_list,
                         max_depth = max_depth_list,
                         OOB_error = NA)
  results <- readRDS("sims/rf_results.RDS")
  results <- results |> filter(num_trees != 200)
  
  
  # Loop through hyperparameters and fit models
  for (i in 11:nrow(results)) {
    set.seed(425)  # Ensure reproducibility
    rf_tuned <- ranger(Outcome ~ ., 
                       data = model_data, 
                       num.trees = results$num_trees[i], 
                       mtry = results$mtry[i],
                       max.depth = results$max_depth[i],
                       importance = "impurity",
                       verbose = TRUE)
    
    # Store the OOB error
    results$OOB_error[i] <- rf_tuned$prediction.error
  }
  saveRDS(results, "sims/rf_results.RDS")
  
  set.seed(425)
  best_params <- results[which.min(results$OOB_error), ]
  rf_model <- ranger(Outcome ~ ., 
                   data = model_data, 
                   num.trees = best_params$num_trees, 
                   importance = "impurity", 
                   mtry = best_params$mtry,
                   max.depth = best_params$max_depth)
  saveRDS(rf_model, "sims/rf_model.RDS")
} else {
  results <- readRDS("sims/rf_results.RDS")
  rf_model <- readRDS("sims/rf_model.RDS")
}
```

### Performance Evaluation:

The Random Forest model will be evaluated using out-of-bag (OOB) error, accuracy, precision, recall, and F1-score. Variable importance plots will help identify the most influential predictors.

```{r, echo=FALSE}
# Variable importance
# importance <- importance(rf_model)
# varImpPlot(rf_model)
```

### Interpretation:

Random Forests provide insights into the relative importance of predictors, highlighting which spectral, temporal, and spatial features contribute most to land cover classification. #? For example, NDVI and PCA-derived features are expected to rank highly, given their ecological relevance.

### Appropriateness:

Random Forests are well-suited for this problem, as they can handle overlapping class boundaries and complex interactions without requiring prior assumptions about the data. However, they lack interpretability compared to linear models.

## Temporal Models: Sinusoidal Regression

To account for seasonal periodicity observed in NDVI and spectral bands, we introduce sinusoidal regression, which models temporal oscillations as sine and cosine components. These derived features will be incorporated into both linear and non-linear models.

### Model Specification:

$$
f(t) = A \cdot \sin(2 \pi f t + \phi) + B \cdot \cos(2 \pi ft + \phi)
$$

Here:

-   $t$ represents the temporal variable (e.g., the numeric representation of `season`)
-   $A$ and $B$ are the amplitude coefficients, which are estimated during model training. These coefficients determine the magnitude of the oscillation and capture the contribution of the sine and cosine terms to the overall periodic pattern.
-   $f$ denotes the frequency of the oscillation, which corresponds to the natural periodicity of the phenomenon under study. For seasonal data divided into four quarters (Winter, Spring, Summer, Fall), $f = \frac{1}{4}$, indicating one full cycle per year.
-   $\phi$ represents the phase shift, accounting for the starting point of the oscillation. Since the data aligns naturally with the seasons (e.g., starts in the Winter), we assume $\phi$ to be 0 to simplify the model.

Implementation:

```{r, echo=FALSE}
# # Create sine/cosine features
# model_data$sin_month <- sin(2 * pi * as.numeric(model_data$Season) / 4)
# model_data$cos_month <- cos(2 * pi * as.numeric(model_data$Season) / 4)
# 
# # Fit sinusoidal regression (logistic model example)
# sinusoidal_model <- multinom(Outcome ~ sin_month + cos_month + NDVI, data = model_data)
# summary(sinusoidal_model)
```

## Model Comparison and Validation

To compare the performance of the models (logistic regression, Random Forests, and sinusoidal extensions), we will use cross-validation. Model evaluation metrics, such as accuracy, precision, recall, and F1-score, will guide the selection of the best-performing model.

```{r, echo=FALSE}
# Cross-validation setup
# train_control <- trainControl(method = "cv", number = 5)
# rf_cv <- train(Outcome ~ ., data = model_data, method = "rf", trControl = train_control)
```

## Section Conclusion

This section details the implementation of multiple classification models, including logistic regression (linear baseline), Random Forests (non-linear, ensemble), and sinusoidal regression (temporal modeling). Each model addresses specific challenges identified in the data exploration phase, such as overlapping class boundaries, temporal periodicity, and spatial dependencies. The next section will visualize and interpret the results, providing a comparative analysis of model performance and insights into the relationships between predictors and land cover classes.

## Visualization and interpretation of the results

Create visualizations of the results when appropriate, focusing on visualizations that

-   help describe aspects of the results that have real-world interpretation
-   help the reader understand how the model addresses the problem you are studying.

**Visualizations are one of the most powerful ways to communicate information to the reader, so it is important to spend time producing clear, descriptive, eye-catching visualizations.**

Discuss the results of the model or models you chose, and describe how they are related to the problem statement or question that you were trying to answer in the project.

If you have built multiple models or types of analysis, compare the measures of performance and the ease of interpretability across models or types of analysis, stating which model or models performed best, and which model or models were most interpretable. Finally, decide which model or type of analysis is best for your particular problem based on some combination of performance and interpretability.

# Conclusions and Recommendations {#conclusions-recs}

One or two paragraphs stating conclusions, recommendations, and ideas for future work and improvements.

# References

List any references for your data source(s), other work or results, etc.
